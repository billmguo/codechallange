https://medium.freecodecamp.org/recognizing-traffic-lights-with-deep-learning-23dae23287cc


多patch划分主要是利用人脸不同patch之间的互补信息增强识别性能。
尤其是多个patch之间的融合能有效提升遮挡情况下的识别性能。当前，
在LFW评测中超过99.50%的结果大多数是由多个patch融合得到。

经过验证较优秀的人脸特征抽取卷积神经网络包括：Deep-ID系列、
VGG-Net、ResNet、Google Inception结构。读者可以根据自己对
精度及效率的需求选择合适的网络。本文以19层resnet举例。

多任务学习主要是利用其他相关信息提升人脸识别性能。本文以性别和种族识别
为例，这两种属性都是和具体人的身份强相关的，而其他的属性如表情、
年龄都没有这个特点。我们在resnet的中间层引出分支进行种族和性别的
多任务学习，这样CNN网络的前几层相当于具有了种族、性别鉴别力的高层语义信息，
在CNN网络的后几层我们进一步学习了身份的细化鉴别信息。同时，训练集中样本的性别和种族属性可以通过一个baseline分类器进行多数投票得到。

多loss融合主要是利用不同loss之间的互补特性学习出适当的人脸特征向量，
使得类内差尽可能小，类间差尽可能大。当前人脸识别领域较为常用的集中
loss包括：pair-wise loss、triplet loss、softmax loss、center loss等。
其中triplet loss直接定义了增大类内类间差gap的优化目标，但是在具体工程实践中，其trick较多，
不容易把握。而最近提出的center loss，结合softmax loss，能较好地度量特征空间中的类内、类间
差，训练配置也较为方便，因此使用较为广泛。

通过多个patch训练得到的模型将产生多个特征向量，如何融合多特征向量进行最终的身份识别也是一个
重要的技术问题。较为常用的方案包括：特征向量拼接、分数级加权融合以及决策级融合（如投票）等。



（1）、多人相关任务放在一起学习，有相关的部分，但也有不相关的部分。当学习一个任务（Main task）
时，与该任务不相关的部分，在学习过程中相当于是噪声，因此，引入噪声可以提高学习的泛化（generalization）
效果。

（2）、单任务学习时，梯度的反向传播倾向于陷入局部极小值。多任务学习中不同任务的局部极小值处于不同的位置，
通过相互作用，可以帮助隐含层逃离局部极小值。

（3）、添加的任务可以改变权值更新的动态特性，可能使网络更适合多任务学习。比如，多任务并行学习，
提升了浅层共享层（shared representation）的学习速率，可能，较大的学习速率提升了学习效果。

（4）、多个任务在浅层共享表示，可能削弱了网络的能力，降低网络过拟合，提升了泛化效果。
